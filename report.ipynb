{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudipsiwakoti/ML2019_ID_12956936/blob/master/report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8UQ1L1ofdUW",
        "colab_type": "text"
      },
      "source": [
        "# **Critical Review on Gradient Based Learning Applied To Document Recognition**\n",
        "\n",
        "## **Assignment 1**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Student ID: 12956936\n",
        "### Student Name: Sudip Siwakoti\n",
        "\n",
        "link to Github: https://github.com/sudipsiwakoti/ML2019_ID_12956936/blob/master/report.ipynb\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hg8Lg8rga3F",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "This report is a literature review based on article on Gradient Based Learning and its application for document recognition and specifically focused on advantages of Convolutional Neural Networks and its application in the domain. There are many different types of neural networks and CNN is a special type of multiple layer neural network use for pattern recognition and used in my computer vision application. This article specifically investigates into the process and methods used for document recognition, hand-written character recognition and online handwriting recognition at the time of publication. At the time of the publication of the article, Le-Net5 was the most advanced Convolutional Neural Network while there were other methods like SVM, KNN, VSVM, etc available as well. Writer also emphasises on the fact how earlier methods required designer need to hand crafted feature extractor which use to be time consuming and labour and compute intensive. Meanwhile, the system could not be generalised and needed to be changed with individual system. Convolution neural network had automated feature extraction methods which one of the major attractive advantage over other system. One of the best examples of this is if you are building a model using CNN you can use a pretrained model from VGG16, RasNet (2015), Google Inception models, etc to boost the performance of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htLePNZ8ggGU",
        "colab_type": "text"
      },
      "source": [
        "# Content\n",
        "The objective of this paper is to investigate on the benefits of Gradient based learning using Graph Transformer Network over the classical methods of heuristic segmentation algorithm for pattern recognition. Classical heuristic methods  struggled with high-dimensional data and requires maximum pre-processing even with low-dimensional data while gradient based learning using GTN significantly reduces the requirement for pre-processing while being able to work with high-dimensional data which is the one of the reason CNN is less compute intensive. The main challenge that writer has tries to address in this article is the challenge of handwriting recognition and online handwriting recognition with gradient based learning using GTN. Considering the high variability of the handwriting dataset and requirement of invariable model for handwriting recognition, different set of experiment were conducted. Writer successfully combined different classifiers like boosting with LeNet-4 to increase performance of the model. In the experiment, writer tested the problem with many classifiers such as nearest neighbour, linear and pairwise classifier, polynomial classifier, RBFN, etc to validate and compare the results of gradient based learning using GTN. This article also elaborates on how gradient based learning has eliminated the requirement for hand crafted feature extraction and introduced use of automatic learning for feature extraction. The second part of the experiment demonstrates the advantage of Space Displacement Neural Network (SSDN) over classical Heuristic Over-Segmentation and resilience of SDNN to noise in the data. During the experiment, to create real-world scenario of data noise writer introduces 10% degradation on training sample with salt and paper using random pixel inversion where Heuristic Over-segmentation failed because of the noise while SDNN was not affected by the degradation of data quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9peZtzHgmcI",
        "colab_type": "text"
      },
      "source": [
        "# Innovation\n",
        "This paper cannot be considered innovative base on the facts presented in it as it mainly focuses on the comparison of existing methods in the industry. Saying that, I would consider this paper to be of great motivation for someone starting to learn Neural Networks as it demonstrates how multiple different classifier can be combined to achieve better results. The experiment conducted by the team of writer was the recreation of the existing Le-Net1, LeNet4 and LeNet5 for comparison of the performance and analysis of efficiency of these CNN methods with other existing methods like SVM, VSVM, KNN, polynomial and linear methods, etc. In the first experiment, the writer states that using LeNet5 model they were able to achieve 0.8% error on test set with some modification of dataset and also where able to achieve 0.7% error on boosted LeNet4 model while SVM and VSVM were able to achieve 1% and 1.1% error on test set with 60% increase computational cost demonstrating the superior performance and efficiency of Convolutional Neural Network. In the second experiment, SDNN model is used to demonstrate the noise resilience of the SDNN model over classical method and along with that writer also conducted some experiment. In the third major experiment they combine multiple classifier to create a better check recognition system with better efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjpuu6mUgovB",
        "colab_type": "text"
      },
      "source": [
        "# Technical Quality\n",
        "After reading through the paper, I have developed a mixed sentiment to the technical quality of the paper. Firstly, talking about the quality of the results are of high standards as they have used the error rate of test set rather than training set but I would have loved to see training sets error rate as well as this would have given me additional information on the method they have implemented. Secondly, they have taken extra steps to compare their findings with large number of classifiers to validate the results. Along with that they also compared their classifier with modified version of the classifier and one of the example was implementing boosting with LeNet4 for better results. Intention of their conclusion from the experiment was not demote any other classifier as incapable but rather they suggested on how implementation of Gradient based learning and GTN along with other classifier can optimise the system. This process can be seen in the experiment in section X where they implement different methods to achieve better results for Check Reading System. My only criticism on the technical quality is that if the article had included segmented system diagram with code snippet used would have made the experiment easier to recreate by any person reading it. Based on my level of understanding, I would not be able to recreate the experiments just based on the literature presented in the paper. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHmVz3XlgxPT",
        "colab_type": "text"
      },
      "source": [
        "# Application and X-factor\n",
        "As no additional technique has been purposed by the paper as the paper is more of a review of the existing technique. Though, saying that this paper has suggested on usefulness and relevance of gradient based minimisation methods as a general organisation principle for learning in large systems. The results of paper could be used to apply it to other domain of computer vision such as voice recognition, facial recognition and many more. \n",
        "Based on my reading I would agree with the view of the writer and suggest that on any application domain of machine learning can use the conclusion of this paper which is suggestive of application and integration of different classifier to improve the overall performance. This can help in eliminating the constraint within a classifier. Also, this paper does not use application of HMM with gradient based learning architectural and training criterion and it is can be an interesting subject of further investigation. It has been long time since the paper has been published there has been significant development in the field and similar investigation into newer approaches can be of interest for emerging data scientists and engineers. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6qrTuWVhARl",
        "colab_type": "text"
      },
      "source": [
        "# Presentation\n",
        "In my personal view I would consider quality of presentation of the paper not to be reader friendly. Specifically, it was very difficult to differentiate between the background of the technology used and experiment conducted by the writer of the paper. Experiments should have been labelled appropriately to differentiate. Also, if the document was arranged in single column format it would have been easier to follow with presented tables and figures without having to go to next page and back. This created a bit of hassle while reading through the paper. Spotting of heading in between the lines would have been easier if they were highlighted along with use of indexing and sub indexing for appropriate heading and subheadings rather than using alphabets and roman numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNeLqJxvhFBC",
        "colab_type": "text"
      },
      "source": [
        "# Refrences\n",
        "\n",
        "\n",
        "> LeCun. Y, Bottou. L, Bengio. Y, Haffner. P 1998, 'Gradient Based Learning Applied to Document Recognition', Gradient Based Learning Applied to Document Recognition, vol. 86, no. 11, pp. 2278-324.\n",
        "\n"
      ]
    }
  ]
}